{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "colab_type": "code",
    "id": "Je3hB9kIreou",
    "outputId": "4f904466-1046-4529-f36b-1166f84a9453"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 nan]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' nan 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]]\n",
      "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"Data.csv\")\n",
    "X = df.iloc[:, :-1].values\n",
    "Y = df.iloc[:, -1].values\n",
    "\n",
    "print (X)\n",
    "print (Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2uTC3mZ16R58"
   },
   "source": [
    "**Handling Missing values**\n",
    "\n",
    "1.   ignore them i.e delete the whole row - useful incase of large ds\n",
    "2.   replace with (mean-done freq) or (median) or (mode-useful in categorical var)\n",
    "\n",
    "useful lib is scikitlearn-sklearn[pckg]impute[module] SimpleImputer[class]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "colab_type": "code",
    "id": "gtEr1fy77B29",
    "outputId": "88c631b1-a304-47e6-b3f0-d92f98f0f01d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 63777.77777777778]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' 38.77777777777778 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "##creating obj for SimpleImputer Class\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy = 'mean')\n",
    "##fit() to find and compute the mean\n",
    "imputer.fit(X[:, 1:3]) ##all rows and all numerical col in X\n",
    "##transform to replace the nan by mean val\n",
    "X[:, 1:3] = imputer.transform(X[:, 1:3])\n",
    "print (X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H1aReYT47zGo"
   },
   "source": [
    "**Encoding Categorical var**\n",
    "we can encode in into numeric data like 0,1,2,3.... but the computer tries to find a series of repetition in them and learn from it-- therfore to avoid it we use binary encoding like 000,001,010...called OneHotEncoding technique\n",
    "\n",
    "in DV-Y like Yes or No categ we can use 0/1\n",
    "\n",
    "1.   IV-X : compose module in sklearn package - ColumnTransformer class &\n",
    "preprocessing module -  OneHotEncoder class\n",
    "\n",
    "need to convert it into numpy array coz fit_transform() doesn't give a numpy array o/p\n",
    "2. DV-Y : we use LabelEncoder class\n",
    "noneed to convert it into a numpy array class. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "colab_type": "code",
    "id": "Z2NgJjMa9y3X",
    "outputId": "77470e2c-a334-4043-ddd2-0922ca7a97bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0 0.0 0.0 44.0 72000.0]\n",
      " [0.0 0.0 1.0 27.0 48000.0]\n",
      " [0.0 1.0 0.0 30.0 54000.0]\n",
      " [0.0 0.0 1.0 38.0 61000.0]\n",
      " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
      " [1.0 0.0 0.0 35.0 58000.0]\n",
      " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
      " [1.0 0.0 0.0 48.0 79000.0]\n",
      " [0.0 1.0 0.0 50.0 83000.0]\n",
      " [1.0 0.0 0.0 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "##creating object for ColumnTransfer class\n",
    "## transformers argument = 3 things to be specified - method, name of method, column you want to apply the method\n",
    "##here the method = encoder, name = onehotencoder(), column = 0th\n",
    "##remainder we give a code word like 'passthrough'\n",
    "ct = ColumnTransformer(transformers = [('encoder', OneHotEncoder(), [0])], remainder = 'passthrough')\n",
    "##we have fit_transform() function --> but it doesnt return a numpy array so we use np.array() and convert the o/p of it.\n",
    "X = ct.fit_transform(X)\n",
    "print (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "h978LgrJicsl",
    "outputId": "9c38b5ed-f25f-4aaa-aeb7-00bb8615ac06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "##creating object of LabelEncoder\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(Y)\n",
    "print (Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uE0CUrc4jwhW"
   },
   "source": [
    "Apply **Feature Scaling** -(scaling the range of all feat to prevent dominance of one feat over another) after Splitting DS into Test and Train set  --- done after splitting to prevent *information leakage of test set before the training is done.*\n",
    "\n",
    "splitting into X_train, X_test, Y_train, Y_test ---> returned by train_test_split() of train_test_split fn of model_selection module of scikitlearn pckg. The fn i/p are matrix of features of X, Dep var vector Y, test set split size, fix the random seed to get same split always coz train_test_split() splits the DS randomly each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gfzRJ0zj5cQ0"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 154
    },
    "colab_type": "code",
    "id": "dmARI8UIOODx",
    "outputId": "b2229a85-144a-486a-8287-df8f39ca358a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 0.0 1.0 38.77777777777778 52000.0]\n",
      " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
      " [1.0 0.0 0.0 44.0 72000.0]\n",
      " [0.0 0.0 1.0 38.0 61000.0]\n",
      " [0.0 0.0 1.0 27.0 48000.0]\n",
      " [1.0 0.0 0.0 48.0 79000.0]\n",
      " [0.0 1.0 0.0 50.0 83000.0]\n",
      " [1.0 0.0 0.0 35.0 58000.0]]\n"
     ]
    }
   ],
   "source": [
    "print (x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "l7NEd18QOOXQ",
    "outputId": "e94b700c-a49f-40b8-cb61-a2e4e60aa896"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 1.0 0.0 30.0 54000.0]\n",
      " [1.0 0.0 0.0 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "print (x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Nph8jZP3OOie",
    "outputId": "16fb9a1b-d7c5-4a80-ff8c-1a1256f6fe35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print (y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yEZ49qu0OOvx",
    "outputId": "d5152171-70da-4c7a-f59b-d3182cdf0b96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "print (y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CjMYSaYvOx8q"
   },
   "source": [
    "**Feature Scaling**\n",
    "done only on x_train-fit_transform and x_test-only transform(no fit coz x_train should be new data for prediction model) to get the congruent scalar.\n",
    "'fit' calc the mean and std_dev, \n",
    "'transform' performs the standardization formula.\n",
    "\n",
    "2ways -  \n",
    "\n",
    "1.   standardization-can be done always\n",
    "2.   normalization-can be done when the feature variables are normaolised values\n",
    "\n",
    "noneed to perform Feature scaling on all X var - i.e on *dummy variables* like encoded categ var no need to apply, and on numerical var like 'age', big range numerical var like 'salary' we should apply\n",
    "\n",
    "sklearn.preprocessing module --  StandardScaler Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DadbO3iYVit2"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()  ##no i/p param\n",
    "x_train[:, 3:] = sc.fit_transform(x_train[:, 3:])\n",
    "x_test[:, 3:] = sc.transform(x_test[:, 3:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 154
    },
    "colab_type": "code",
    "id": "hmIaAjxxZS0H",
    "outputId": "660d3e6f-e062-4407-891b-dd951e4113f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 0.0 1.0 -0.19159184384578545 -1.0781259408412425]\n",
      " [0.0 1.0 0.0 -0.014117293757057777 -0.07013167641635372]\n",
      " [1.0 0.0 0.0 0.566708506533324 0.633562432710455]\n",
      " [0.0 0.0 1.0 -0.30453019390224867 -0.30786617274297867]\n",
      " [0.0 0.0 1.0 -1.9018011447007988 -1.420463615551582]\n",
      " [1.0 0.0 0.0 1.1475343068237058 1.232653363453549]\n",
      " [0.0 1.0 0.0 1.4379472069688968 1.5749910381638885]\n",
      " [1.0 0.0 0.0 -0.7401495441200351 -0.5646194287757332]]\n"
     ]
    }
   ],
   "source": [
    "print (x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "KyIUm5a4ZVoJ",
    "outputId": "2409bb7c-c6d7-460b-9f2b-ed5f0796105e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 1.0 0.0 -1.4661817944830124 -0.9069571034860727]\n",
      " [1.0 0.0 0.0 -0.44973664397484414 0.2056403393225306]]\n"
     ]
    }
   ],
   "source": [
    "print (x_test) "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "datapreprocessing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
